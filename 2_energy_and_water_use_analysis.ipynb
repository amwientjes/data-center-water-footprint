{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Energy and water use anlysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Import libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "from functions.data_etl.file_io import read_gdf_from_csv\n",
    "from functions.data_etl.geocoding import country_alpha3_to_alpha2\n",
    "from functions.data_etl.imputation import PowerCapacityScenario\n",
    "from functions.energy_and_water_use.climate_zones import read_koppen_tif\n",
    "from functions.energy_and_water_use.direct_energy_water_use import (\n",
    "    assign_pue_wue,\n",
    "    assign_scenarios,\n",
    ")\n",
    "from functions.energy_and_water_use.indirect_water_use import (\n",
    "    assign_multi_source_grid_zones,\n",
    "    assign_water_use_to_power_plants,\n",
    "    combine_dcs_and_pps,\n",
    "    get_power_grid_stats,\n",
    "    replace_zones_with_nearest,\n",
    "    results_average_wue_pue,\n",
    "    results_summary,\n",
    ")\n",
    "from functions.energy_and_water_use.regression_analysis import (\n",
    "    mixed_effects_model_analysis,\n",
    "    plot_col_and_log_transform_histograms,\n",
    "    polynomial_regression_analysis,\n",
    "    predict_white_space_from_total_space,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting input and output paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input paths\n",
    "IMPUTED_DATA_CENTERS_INPUT_PREFIX = Path(\"data/outputs/1_data_etl/data_centers_impute_\")\n",
    "INPUTS_DIR = Path(\"data/inputs/2_energy_and_water_use\")\n",
    "\n",
    "# Output paths\n",
    "OUTPUT_DIR = Path(\"data/outputs/2_energy_and_water_use/\")\n",
    "FIGURE_DIR = Path(\"data/outputs/figures/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling specifications\n",
    "\n",
    "In order to calculate energy and water use, we need the estimate of gross power for each data center. 65% of data centers have critical power provided. For the rest, this needs to be scaled from total area or white area. Hence we investigate the relationship between the two.\n",
    "\n",
    "First, the variables are checked for normal distribution\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set power capacity scenarios (minimum, maximum, and average)\n",
    "power_scenarios = tuple(scenario.value for scenario in PowerCapacityScenario)\n",
    "imputation_scenarios = (*power_scenarios, \"baseline\")  # Add baseline scenario without imputation\n",
    "\n",
    "# Data center specifications under different power capacity scenarios, including imputation baseline\n",
    "data_centers_imputation_scenarios = {\n",
    "    scenario: pd.read_csv(f\"{IMPUTED_DATA_CENTERS_INPUT_PREFIX}{scenario}.csv\") for scenario in imputation_scenarios\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histograms and log transformed histograms of critical power, total space, and white space\n",
    "for column, color in [(\"critical_power_mw\", \"red\"), (\"total_space_m2\", \"blue\"), (\"white_space_m2\", \"lightblue\")]:\n",
    "    plot_col_and_log_transform_histograms(data_centers_imputation_scenarios[\"baseline\"], column, color, FIGURE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All variables are highly skewed. When log transformed, the variables appear more normally distributed.\n",
    "\n",
    "In order to predict critical power, it is easier to have a variable with non missing values for all cases predicted (rather than a mix of missing and not missing between white and total space). Therefore, it may be best to first estimate white space from total space for the 13% which are missing it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatterplot of log total space vs log white space\n",
    "plt.scatter(\n",
    "    np.log1p(data_centers_imputation_scenarios[\"baseline\"][\"total_space_m2\"]),\n",
    "    np.log1p(data_centers_imputation_scenarios[\"baseline\"][\"white_space_m2\"]),\n",
    "    color=\"blue\",\n",
    ")\n",
    "plt.xlabel(\"log Total space (m²)\")\n",
    "plt.ylabel(\"log White space (m²)\")\n",
    "plt.title(\"log Total Space vs log White space\")\n",
    "plt.savefig(f\"{FIGURE_DIR}/scatterplot_log_total_space_vs_log_white_space.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears that there is a generally linear relationship between the two. Hence, we first use linear regression to predict missing white space values when gross power is missing and only total space is present.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Fit: log white_space_m2 = 0.8787 * log total_space_m2 + 0.1127\n",
      "INFO:functions.energy_and_water_use.regression_analysis:R2: 0.7444\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "INFO:root:Fit: log white_space_m2 = 0.8787 * log total_space_m2 + 0.1127\n",
      "INFO:functions.energy_and_water_use.regression_analysis:R2: 0.7444\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "INFO:root:Fit: log white_space_m2 = 0.8787 * log total_space_m2 + 0.1127\n",
      "INFO:functions.energy_and_water_use.regression_analysis:R2: 0.7444\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n",
      "INFO:root:Fit: log white_space_m2 = 0.8787 * log total_space_m2 + 0.1127\n",
      "INFO:functions.energy_and_water_use.regression_analysis:R2: 0.7444\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/.venv/lib/python3.13/site-packages/sklearn/utils/validation.py:2732: UserWarning: X has feature names, but LinearRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Predicting white space from total space for different power scenarios\n",
    "for scenario in imputation_scenarios:\n",
    "    data_centers_imputation_scenarios[scenario] = predict_white_space_from_total_space(\n",
    "        data_centers_imputation_scenarios[\"baseline\"], data_centers_imputation_scenarios[scenario]\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial regression\n",
    "\n",
    "There are multiple ways to predict critical power from area. First, polynomial regression is tested.\n",
    "\n",
    "Polynomial regression with degree 2 is used to fill in the 34% of missing gross power. This is done with the input of white space. Other variables are excluded to prevent over fitting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:functions.energy_and_water_use.regression_analysis:3-Fold CV - Mean MAE: 0.5384\n",
      "INFO:functions.energy_and_water_use.regression_analysis:5-Fold CV - Mean MAE: 0.5381\n",
      "INFO:functions.energy_and_water_use.regression_analysis:R² Score: 0.6122\n",
      "INFO:functions.energy_and_water_use.regression_analysis:RMSE: 0.7166\n"
     ]
    }
   ],
   "source": [
    "critical_power_predicted_polynomial = polynomial_regression_analysis(\n",
    "    data_centers_imputation_scenarios[\"avg\"],\n",
    "    \"critical_power_mw\",\n",
    "    [\"white_space_m2\"],\n",
    "    polynomial_degree=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed-effect modeling\n",
    "\n",
    "Mixed-effect modeling is used with the random effect of company. This produces the highest r2 and best overall fit. Therefore, this method is used.\n",
    "\n",
    "First, we find the percent of the data where the company or country is not in the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nan% of data points in the prediction set have a company not in the training set\n",
      "nan% of data points in the prediction set have a country not in the training set\n"
     ]
    }
   ],
   "source": [
    "# Define the training data set\n",
    "training_data = data_centers_imputation_scenarios[\"avg\"].dropna(subset=[\"white_space_m2\", \"critical_power_mw\"])\n",
    "\n",
    "# Find the data which needs to be predicted\n",
    "data_centers_to_predict = data_centers_imputation_scenarios[\"avg\"][\n",
    "    data_centers_imputation_scenarios[\"avg\"][\"critical_power_mw\"].isna()\n",
    "]\n",
    "\n",
    "to_predict = data_centers_to_predict[\"company\"].unique()\n",
    "training = training_data[\"company\"].unique()\n",
    "not_in_training = set(to_predict) - set(training)\n",
    "\n",
    "# Print the percent of companies and countries in the prediction set that are not in the training set\n",
    "entities = [\"company\", \"ISO_A3\"]\n",
    "entity_names = [\"company\", \"country\"]\n",
    "\n",
    "for entity, entity_name in zip(entities, entity_names, strict=False):\n",
    "    to_predict = data_centers_to_predict[entity].unique()\n",
    "    training = training_data[entity].unique()\n",
    "    not_in_training = set(to_predict) - set(training)\n",
    "\n",
    "    # Print the percent of data points in the set to predict whose entity is not in the training set\n",
    "    percent_data_points = data_centers_to_predict[entity].isin(not_in_training).mean() * 100\n",
    "    print(\n",
    "        f\"{percent_data_points:.2f}% of data points in the prediction set have a {entity_name} not in the training set\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:functions.energy_and_water_use.regression_analysis:                 Mixed Linear Model Regression Results\n",
      "========================================================================\n",
      "Model:            MixedLM Dependent Variable: Q(\"log_critical_power_mw\")\n",
      "No. Observations: 2071    Method:             REML                      \n",
      "No. Groups:       605     Scale:              0.4004                    \n",
      "Min. group size:  1       Log-Likelihood:     -2264.7540                \n",
      "Max. group size:  198     Converged:          Yes                       \n",
      "Mean group size:  3.4                                                   \n",
      "-------------------------------------------------------------------------\n",
      "                         Coef.   Std.Err.     z     P>|z|  [0.025  0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                -2.384     0.097  -24.701  0.000  -2.573  -2.195\n",
      "Q(\"log_white_space_m2\")   0.558     0.012   45.761  0.000   0.534   0.582\n",
      "Group Var                 0.294     0.060                                \n",
      "========================================================================\n",
      "\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model R2: 0.749597\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model MSE: 0.337501\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/functions/energy_and_water_use/regression_analysis.py:365: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[f\"Mixed-effect log_{output_cols}\"] = predictions\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/functions/energy_and_water_use/regression_analysis.py:368: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[f\"Mixed-effect {output_cols}\"] = np.expm1(missing_data[f\"Mixed-effect log_{output_cols}\"])\n",
      "INFO:functions.energy_and_water_use.regression_analysis:                 Mixed Linear Model Regression Results\n",
      "========================================================================\n",
      "Model:            MixedLM Dependent Variable: Q(\"log_critical_power_mw\")\n",
      "No. Observations: 2071    Method:             REML                      \n",
      "No. Groups:       605     Scale:              0.4004                    \n",
      "Min. group size:  1       Log-Likelihood:     -2264.7540                \n",
      "Max. group size:  198     Converged:          Yes                       \n",
      "Mean group size:  3.4                                                   \n",
      "-------------------------------------------------------------------------\n",
      "                         Coef.   Std.Err.     z     P>|z|  [0.025  0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                -2.384     0.097  -24.701  0.000  -2.573  -2.195\n",
      "Q(\"log_white_space_m2\")   0.558     0.012   45.761  0.000   0.534   0.582\n",
      "Group Var                 0.294     0.060                                \n",
      "========================================================================\n",
      "\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model R2: 0.749597\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model MSE: 0.337501\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/functions/energy_and_water_use/regression_analysis.py:365: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[f\"Mixed-effect log_{output_cols}\"] = predictions\n",
      "/Users/audreywientjes/Library/CloudStorage/OneDrive-UniversiteitLeiden/data-center-water-footprint/functions/energy_and_water_use/regression_analysis.py:368: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  missing_data[f\"Mixed-effect {output_cols}\"] = np.expm1(missing_data[f\"Mixed-effect log_{output_cols}\"])\n",
      "INFO:functions.energy_and_water_use.regression_analysis:                 Mixed Linear Model Regression Results\n",
      "========================================================================\n",
      "Model:            MixedLM Dependent Variable: Q(\"log_critical_power_mw\")\n",
      "No. Observations: 4009    Method:             REML                      \n",
      "No. Groups:       1067    Scale:              0.2323                    \n",
      "Min. group size:  1       Log-Likelihood:     -3194.6810                \n",
      "Max. group size:  234     Converged:          Yes                       \n",
      "Mean group size:  3.8                                                   \n",
      "-------------------------------------------------------------------------\n",
      "                         Coef.   Std.Err.     z     P>|z|  [0.025  0.975]\n",
      "-------------------------------------------------------------------------\n",
      "Intercept                -2.267     0.051  -44.840  0.000  -2.366  -2.168\n",
      "Q(\"log_white_space_m2\")   0.541     0.007   81.995  0.000   0.528   0.554\n",
      "Group Var                 0.146     0.029                                \n",
      "========================================================================\n",
      "\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model R2: 0.821635\n",
      "INFO:functions.energy_and_water_use.regression_analysis:Mixed-Effects Model MSE: 0.201551\n"
     ]
    }
   ],
   "source": [
    "# Fit a mixed-effect model for each power scenario\n",
    "for scenario in power_scenarios:\n",
    "    data_centers_imputation_scenarios[scenario] = mixed_effects_model_analysis(\n",
    "        data_centers_imputation_scenarios[scenario],\n",
    "        input_cols=\"white_space_m2\",\n",
    "        output_cols=\"critical_power_mw\",\n",
    "        categorical_col=\"company\",\n",
    "        display_results=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv to use for full list of data centers without scenarios\n",
    "data_centers_imputation_scenarios[\"min\"].to_csv(f\"{OUTPUT_DIR}/data_centers_no_scenarios.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging\n",
    "\n",
    "For scenario modelling it is easiest to have the min and max gross power estimates for the big 5 in one data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Power scenario column\n",
    "for scenario in power_scenarios:\n",
    "    data_centers_imputation_scenarios[scenario][\"power_scenario\"] = scenario\n",
    "\n",
    "# Concatenating the dataframes\n",
    "data_centers = pd.concat(\n",
    "    [data_centers_imputation_scenarios[scenario] for scenario in power_scenarios], ignore_index=True\n",
    ")\n",
    "\n",
    "# Convert to GeoDataFrame\n",
    "data_centers = gpd.GeoDataFrame(\n",
    "    data_centers,\n",
    "    geometry=gpd.points_from_xy(data_centers.longitude, data_centers.latitude),\n",
    "    crs=\"EPSG:4326\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing data center size\n",
    "\n",
    "In line with Lei & Masanet (2022), we categorize data centers small, medium and large by total space.\n",
    "\n",
    "- Small: 0-100 m<sup>2</sup>\n",
    "- Medium: 100-2000 m<sup>2</sup>\n",
    "- Large: >2000 m<sup>2</sup>\n",
    "\n",
    "These categories must first also be equivalated to power using the mixed-effect model. By observing the data, this translates to:\n",
    "\n",
    "- Small: 0-1 MW\n",
    "- Medium: 1-4 MW\n",
    "- Large: >4 MW\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a new category for size of data center based on power\n",
    "data_centers[\"size\"] = pd.cut(\n",
    "    data_centers[\"critical_power_mw\"],\n",
    "    bins=[0, 1, 4, float(\"inf\")],\n",
    "    labels=[\"small\", \"medium\", \"large\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min total critical power for operational data centers: 61.20 GW\n",
      "Max total critical power for operational data centers: 64.06 GW\n",
      "Avg total critical power for operational data centers: 63.08 GW\n",
      "Min total critical power for planned data centers: 40.34 GW\n",
      "Max total critical power for planned data centers: 41.78 GW\n",
      "Avg total critical power for planned data centers: 41.93 GW\n"
     ]
    }
   ],
   "source": [
    "# Find the total critical power for operational data centers for each power scenario\n",
    "for is_operational in [True, False]:\n",
    "    for scenario in power_scenarios:\n",
    "        total_critical_power = data_centers[\n",
    "            (data_centers[\"operational\"] == is_operational) & (data_centers[\"power_scenario\"] == scenario)\n",
    "        ][\"critical_power_mw\"].sum()\n",
    "        status_str = \"operational\" if is_operational else \"planned\"\n",
    "        print(\n",
    "            f\"{scenario.capitalize()} total critical power for {status_str} data centers: \"\n",
    "            f\"{total_critical_power / 1000:.2f} GW\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assigning ASHRAE climate zones\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data on climate zones comes from Beck et al. (2023), where Koppen climate classifications are provided with a 0.5 degree resolution. While PUE and WUE values are given relative to ASHRAE climate zones, no global tif/shapefiles are available for this classification system, which was originally created for building design in the U.S. Instead, ASHRAE climate zones are mapped onto the Koppen classification system using [Kudacity cities by Koppen classification](https://www.kudacity.com/cset/by_climate) and [ASHRAE cities by climate zone](https://www.ashrae.org/file%20library/technical%20resources/standards%20and%20guidelines/standards%20addenda/169_2020_a_20211029.pdf), in addition to the [ASHRAE descriptions](https://help.iesve.com/ve2021/ashrae_climate_zones.htm).\n",
    "\n",
    "Koppen climate zones from 1991-2020 weather data are used for the analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Polygonize 1991-2020 climate zones\n",
    "koppen_1991_2020 = read_koppen_tif(input_raster_path=INPUTS_DIR / \"koppen_geiger_tif/1991_2020/koppen_geiger_0p5.tif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, koppen classifications were matched to ASHRAE. Multiple koppen zones fall under one ASHRAE zone, so first we create a dictionary to map one to another.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping each Köppen classification to the corresponding ASHRAE zone\n",
    "koppen_to_ashrae = {\n",
    "    1: \"1A\",\n",
    "    2: \"1A\",\n",
    "    3: \"1A\",\n",
    "    4: \"2B\",\n",
    "    5: \"3B\",\n",
    "    6: \"2A\",\n",
    "    7: \"5B\",\n",
    "    8: \"3A\",\n",
    "    9: \"3C\",\n",
    "    10: \"4C\",\n",
    "    11: \"2A\",\n",
    "    12: \"3A\",\n",
    "    13: \"6B\",\n",
    "    14: \"3A\",\n",
    "    15: \"4A\",\n",
    "    16: \"6B\",\n",
    "    17: \"4B\",\n",
    "    18: \"6B\",\n",
    "    19: \"8\",\n",
    "    20: \"8\",\n",
    "    21: \"6A\",\n",
    "    22: \"5A\",\n",
    "    23: \"8\",\n",
    "    24: \"8\",\n",
    "    25: \"5A\",\n",
    "    26: \"7\",\n",
    "    27: \"8\",\n",
    "    28: \"8\",\n",
    "    29: \"8\",\n",
    "    30: \"8\",\n",
    "}\n",
    "\n",
    "# Map Köppen classifications to ASHRAE zones\n",
    "koppen_1991_2020[\"ashrae_zone\"] = koppen_1991_2020[\"classification\"].map(koppen_to_ashrae)\n",
    "\n",
    "# Dissolve the polygons by ASHRAE zone\n",
    "koppen_1991_2020 = koppen_1991_2020.dissolve(by=\"ashrae_zone\", as_index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the mapped ASHRAE zones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/qf52x40s3gj84v948mly870m0000gn/T/ipykernel_99924/763737261.py:3: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  color_map = plt.cm.get_cmap(\"tab20\", len(unique_zones))\n"
     ]
    }
   ],
   "source": [
    "# Create a mapping of zones to colors\n",
    "unique_zones = sorted(koppen_1991_2020[\"ashrae_zone\"].unique())\n",
    "color_map = plt.cm.get_cmap(\"tab20\", len(unique_zones))\n",
    "zone_colors = {zone: color_map(i) for i, zone in enumerate(unique_zones)}\n",
    "\n",
    "# Plot the map\n",
    "fig, ax = plt.subplots(figsize=(12, 8), subplot_kw={\"projection\": ccrs.Robinson()})\n",
    "\n",
    "# Add each zone to the plot with its corresponding color\n",
    "for zone, color in zone_colors.items():\n",
    "    koppen_1991_2020[koppen_1991_2020[\"ashrae_zone\"] == zone].plot(\n",
    "        ax=ax, transform=ccrs.PlateCarree(), color=color, label=f\"ASHRAE_zone {zone}\"\n",
    "    )\n",
    "\n",
    "# Add a legend outside the plot\n",
    "legend_handles = [\n",
    "    Line2D(\n",
    "        [0],\n",
    "        [0],\n",
    "        marker=\"o\",\n",
    "        color=\"w\",\n",
    "        markerfacecolor=color_map(i),\n",
    "        markersize=10,\n",
    "        label=f\"Zone {zone}\",\n",
    "    )\n",
    "    for i, zone in enumerate(unique_zones)\n",
    "]\n",
    "ax.legend(\n",
    "    handles=legend_handles,\n",
    "    title=\"ASHRAE Climate Zones\",\n",
    "    loc=\"center left\",\n",
    "    bbox_to_anchor=(1, 0.5),\n",
    ")\n",
    "\n",
    "ax.set_axis_off()\n",
    "\n",
    "# Save the plot\n",
    "plt.savefig(f\"{FIGURE_DIR}/ashrae_climate_zones.png\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform spatial join between data centers and climate zones without creating 'index_right' column\n",
    "data_centers = gpd.sjoin(\n",
    "    data_centers,\n",
    "    koppen_1991_2020[[\"ashrae_zone\", \"geometry\"]],\n",
    "    how=\"left\",\n",
    "    predicate=\"within\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Direct energy and water use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matching PUE and WUE values to data centers\n",
    "\n",
    "The WUE and PUE values are taken from Lei & Masanet (2022), which provide best and worst WUE and PUE values under a range of climates and cooling technologies cases. A 50th quantile, medium performance scenario was added taking the average of best and worst.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in PUE & WUE data\n",
    "PUE_WUE_scenarios = pd.read_csv(f\"{INPUTS_DIR}/PUE_WUE_scenarios.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the reported PUE and energy consumption columns as they are mostly missing and the model will overwrite them\n",
    "data_centers = data_centers.drop(columns=[\"Annual electricity consumption (GWh)\", \"PUE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The WUE values from Lei & Masanet (2022) pertain to water consumption of data centers. We want water withdrawal for our analysis in order to incorporate into water scarcity indicators. Hence, we multiply all WUE values by 1.3, a relative ratio between withdrawal and consumption based on Li et al. (2025).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign PUE and WUE values to each data center\n",
    "data_centers = assign_pue_wue(\n",
    "    data_centers,\n",
    "    PUE_WUE_scenarios,\n",
    "    size_to_case_mapping={  # Mapping of data center sizes to technology cases\n",
    "        \"large\": [1, 2],\n",
    "        \"medium\": list(range(3, 8)),\n",
    "        \"small\": list(range(8, 11)),\n",
    "    },\n",
    "    tech_perf_level_to_quantile_mapping={  # Performance levels and their corresponding quantiles\n",
    "        \"best\": 0,\n",
    "        \"medium\": 50,\n",
    "        \"worst\": 100,\n",
    "    },\n",
    "    conversion_factor_consumption_to_withdrawal=1.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenarios\n",
    "\n",
    "5 different scenarios of cooling technology used are defined. The most common scenario, representing the most common technology currently in place, uses Waterside economizer + (water-cooled chiller) in large data centers and Airside economizer + (water-cooled chiller) in medium data centers.\n",
    "\n",
    "Here are the scenarios:\n",
    "\n",
    "| Scenario               | Case Large-Scale | Technology Large-Scale                                          | Case Medium-Scale | Technology Medium-Scale                       | Case Small-Scale | Technology Small-Scale  |\n",
    "| ---------------------- | ---------------- | --------------------------------------------------------------- | ----------------- | --------------------------------------------- | ---------------- | ----------------------- |\n",
    "| Most common | 2                | Waterside economizer + (water-cooled chiller)                   | 3                 | Airside economizer + (water-cooled chiller)   | 10               | Direct expansion system |\n",
    "| Optimized energy use   | 2                | Waterside economizer + (water-cooled chiller)                   | 4                 | Waterside economizer + (water-cooled chiller) | 8                | Water-cooled chiller    |\n",
    "| Optimized water use    | 1                | Airside economizer + adiabatic cooling + (water-cooled chiller) | 6                 | Airside economizer + (air-cooled chiller)     | 9                | Air-cooled chiller      |\n",
    "| Intensive energy use   | 1                | Airside economizer + adiabatic cooling + (water-cooled chiller) | 7                 | Air-cooled chiller                            | 10               | Direct expansion system |\n",
    "| Intensive water use    | 2                | Waterside economizer + (water-cooled chiller)                   | 5                 | Water-cooled chiller                          | 8                | Water-cooled chiller    |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scenarios\n",
    "data_centers = assign_scenarios(\n",
    "    data_centers,\n",
    "    scenario_mappings={\n",
    "        \"large\": {\n",
    "            1: [\"optimized_water_use\", \"intensive_energy_use\"],\n",
    "            2: [\"most_common\", \"optimized_energy_use\", \"intensive_water_use\"],\n",
    "        },\n",
    "        \"medium\": {\n",
    "            3: [\"most_common\"],\n",
    "            4: [\"optimized_energy_use\"],\n",
    "            5: [\"intensive_water_use\"],\n",
    "            6: [\"optimized_water_use\"],\n",
    "            7: [\"intensive_energy_use\"],\n",
    "        },\n",
    "        \"small\": {\n",
    "            9: [\"optimized_water_use\"],\n",
    "            8: [\"optimized_energy_use\", \"intensive_water_use\"],\n",
    "            10: [\"most_common\", \"intensive_energy_use\"],\n",
    "        },\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating annual direct energy and water consumption\n",
    "\n",
    "Gross power represents the data center power capacity, or the IT load. However, this does not account alone for additional energy used (e.g. lighting, operations, or inefficiencies). Therefore, this can be multiplied by the power use effectiveness (PUE) to obtain annual energy consumption, also accounting for the hours in a year, as seen in the equation below.\n",
    "\n",
    "$$\n",
    "DC\\_E_{total} (MWh) = Power (MW) \\times PUE \\left(\\frac{MWh}{MWh}\\right) \\times 8760 \\left(\\frac{hours}{year}\\right)\n",
    "$$\n",
    "\n",
    "For the annual water consumption, the water use efficiency (WUE) represents the water used in litres per kWh of electricity consumed by IT equipment (or gross power). This results in the following equation:\n",
    "\n",
    "$$\n",
    "DC\\_W_{direct} (m^3) = Power (MW) \\times WUE \\left(\\frac{m^3}{MWh}\\right) \\times 8760 \\left(\\frac{hours}{year}\\right)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate annual electricity use (MWh) and direct water use (m3)\n",
    "data_centers[\"annual_electricity_use_MWh\"] = data_centers[\"PUE\"] * data_centers[\"critical_power_mw\"] * 8760  # Hours/yr\n",
    "data_centers[\"annual_direct_water_use_m3\"] = data_centers[\"WUE_withdrawal\"] * data_centers[\"critical_power_mw\"] * 8760"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the results to a csv file\n",
    "data_centers.to_csv(f\"{OUTPUT_DIR}/data_centers_direct_impacts.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yd/qf52x40s3gj84v948mly870m0000gn/T/ipykernel_99924/6304170.py:1: DtypeWarning: Columns (12,16) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data_centers = pd.read_csv(f\"{OUTPUT_DIR}/data_centers_direct_impacts.csv\")\n"
     ]
    }
   ],
   "source": [
    "data_centers = pd.read_csv(f\"{OUTPUT_DIR}/data_centers_direct_impacts.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indirect water use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power plants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data is from the WRI global power plant database version 1.30 (Byers et al., 2018; download [here](https://datasets.wri.org/datasets/global-power-plant-database?))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in power plant data\n",
    "power_plants_gdf = read_gdf_from_csv(INPUTS_DIR / \"globalpowerplantdatabasev130/global_power_plant_database.csv\")\n",
    "data_centers_no_scenarios = read_gdf_from_csv(OUTPUT_DIR / \"data_centers_no_scenarios.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Power grids\n",
    "\n",
    "Assigning power grid zones to data centers and power plants. We primarily used Electricity Maps electricity grid boundaries. For areas without an assigned Electricity Maps grid, we used Ecoinvent grids (Ecoinvent Electricity Networks, 2020). For the remaining few locations, we assigned data centers to their country grids.\n",
    "\n",
    "geogjson link: <https://github.com/electricitymaps/electricitymaps-contrib/blob/master/web/geo/world.geojson>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load electricity maps geojson and ecoinvent grids shapefile\n",
    "electricity_maps_gdf = gpd.read_file(INPUTS_DIR / \"electricity_maps.geojson\")\n",
    "ecoinvent_electricity_grids_gdf = gpd.read_file(INPUTS_DIR / \"ecoinvent_electricity_networks/electricity.shp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign electricity maps zones to power plants and data centers\n",
    "power_plants_with_zone, data_centers_with_zone = (\n",
    "    assign_multi_source_grid_zones(gdf, electricity_maps_gdf, ecoinvent_electricity_grids_gdf)\n",
    "    for gdf in (power_plants_gdf, data_centers_no_scenarios)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:functions.energy_and_water_use.indirect_water_use:Missing zones: ['CW', 'IM', 'NC', 'MC', 'MT', 'LI', 'GG', 'JE', 'PF']\n",
      "INFO:functions.energy_and_water_use.indirect_water_use:Number of data centers in the missing zones: 12\n"
     ]
    }
   ],
   "source": [
    "# For power plants and data centers still without a zone, assign it to the ISO2 code of the country\n",
    "power_plants_with_zone[\"power_grid_zone\"] = power_plants_with_zone[\"power_grid_zone\"].fillna(\n",
    "    power_plants_with_zone[\"country\"].apply(country_alpha3_to_alpha2)  # Power plant data country column is ISO3\n",
    ")\n",
    "\n",
    "data_centers_with_zone[\"power_grid_zone\"] = data_centers_with_zone[\"power_grid_zone\"].fillna(\n",
    "    data_centers_with_zone[\"ISO_A3\"].apply(country_alpha3_to_alpha2)\n",
    ")\n",
    "\n",
    "# Assign remaining data centers without a grid to the nearest grid\n",
    "data_centers_with_zone = replace_zones_with_nearest(data_centers_with_zone, power_plants_with_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assigning water intensities per grid\n",
    "\n",
    "Global median water use intensities in (litres/MWh) from [Jin et al., (2019)](https://doi.org/10.1016/j.rser.2019.109391) and ecoinvent were collected.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read water intensity data\n",
    "wi_column_map = {\n",
    "    \"Fuel type (dataset)\": \"primary_fuel\",\n",
    "    \"median blue water withdrawal of operation (m3/MWh)\": \"water_intensity_m3/MWh\",\n",
    "}\n",
    "\n",
    "water_intensity = pd.read_csv(\n",
    "    INPUTS_DIR / \"glob_median_water_intensity_e_prod.csv\",\n",
    "    usecols=list(wi_column_map.keys()),\n",
    ").rename(columns=wi_column_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign water intensities to power plants\n",
    "power_plants_with_zone = power_plants_with_zone.merge(water_intensity, on=\"primary_fuel\", how=\"left\")\n",
    "\n",
    "# Calculate the water intensity per power grid\n",
    "power_grid_summary = get_power_grid_stats(power_plants_with_zone, data_centers_with_zone)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the full data centers dataframe with the data centers with zones\n",
    "data_centers_with_zone = data_centers.merge(\n",
    "    data_centers_with_zone[[\"company\", \"name\", \"address\", \"power_grid_zone\"]],\n",
    "    on=[\"company\", \"name\", \"address\"],\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "# Assign water intensities to data centers based on the power grids they are connected to\n",
    "data_centers_with_zone = data_centers_with_zone.merge(\n",
    "    power_grid_summary[[\"power_grid_zone\", \"water_intensity_m3/MWh\"]],\n",
    "    on=\"power_grid_zone\",\n",
    "    how=\"left\",\n",
    ").rename(columns={\"water_intensity_m3/MWh\": \"grid_water_intensity_m3/MWh\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate indirect and total water use for each data center\n",
    "data_centers_with_zone[\"indirect_water_use_m3\"] = (\n",
    "    data_centers_with_zone[\"annual_electricity_use_MWh\"] * data_centers_with_zone[\"grid_water_intensity_m3/MWh\"]\n",
    ")\n",
    "data_centers_with_zone[\"total_water_use_m3\"] = (\n",
    "    data_centers_with_zone[\"annual_direct_water_use_m3\"] + data_centers_with_zone[\"indirect_water_use_m3\"]\n",
    ")\n",
    "\n",
    "# Export data centers with water use for all scenarios\n",
    "data_centers_with_zone.to_csv(f\"{OUTPUT_DIR}/data_centers_total_water_use.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a summary of the results with the direct, indirect, and total water use for each scenario\n",
    "water_electricity_use_results = results_summary(data_centers_with_zone)\n",
    "\n",
    "# Export to csv\n",
    "water_electricity_use_results.to_csv(f\"{OUTPUT_DIR}/data_centers_water_electricity_use_summary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the average data center WUE and PUE based on characteristics such as size, climate zone, and power grid zone\n",
    "average_wue_pue = results_average_wue_pue(data_centers_with_zone)\n",
    "\n",
    "# Export to csv\n",
    "average_wue_pue.to_csv(f\"{OUTPUT_DIR}/data_centers_average_PUE_WUE_summary.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline scenario for further analysis\n",
    "\n",
    "The baseline scenario is used for water scarcity modeling, including the baseling cooling mix, average power capacity scenario, and medium technological performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To reduce computational load, set a baseline scenario\n",
    "# This uses power_scenario of 'avg', tech_performance of 'medium', and cooling_tech_scenario of 'baseline'\n",
    "data_centers_baseline = data_centers_with_zone[\n",
    "    (data_centers_with_zone[\"power_scenario\"] == \"avg\")\n",
    "    & (data_centers_with_zone[\"tech_performance\"] == \"medium\")\n",
    "    & (data_centers_with_zone[\"cooling_tech_scenario\"] == \"baseline\")\n",
    "]\n",
    "\n",
    "# Assign water use to power plants\n",
    "power_plants_baseline = assign_water_use_to_power_plants(\n",
    "    data_centers_baseline,\n",
    "    power_grid_summary,\n",
    "    power_plants_with_zone,\n",
    "    consider_op_status=False,\n",
    ")\n",
    "\n",
    "# Assign water use to power plants only based on operational data centers\n",
    "power_plants_operational_planned = assign_water_use_to_power_plants(\n",
    "    data_centers_with_zone,\n",
    "    power_grid_summary,\n",
    "    power_plants_with_zone,\n",
    "    consider_op_status=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "power_plants_baseline.to_csv(f\"{OUTPUT_DIR}/power_plants_water_use_baseline.csv\", index=False)\n",
    "data_centers_baseline.to_csv(f\"{OUTPUT_DIR}/data_centers_water_use_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a combined dataframe of data centers and power plants\n",
    "combined_dcs_pps = combine_dcs_and_pps(\n",
    "    data_centers_df=data_centers_baseline,\n",
    "    power_plants_df=power_plants_baseline,\n",
    "    status=\"all\",\n",
    ")\n",
    "\n",
    "# Only consider operational data centers\n",
    "combined_dcs_pps_operational = combine_dcs_and_pps(\n",
    "    data_centers_df=data_centers_baseline,\n",
    "    power_plants_df=power_plants_operational_planned,\n",
    "    status=\"operational\",\n",
    ")\n",
    "\n",
    "# Only consider planned data centers\n",
    "combined_dcs_pps_planned = combine_dcs_and_pps(\n",
    "    data_centers_df=data_centers_baseline,\n",
    "    power_plants_df=power_plants_operational_planned,\n",
    "    status=\"planned\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export to csv\n",
    "combined_dcs_pps.to_csv(f\"{OUTPUT_DIR}/water_use_dcs_pps_baseline.csv\", index=False)\n",
    "combined_dcs_pps_operational.to_csv(f\"{OUTPUT_DIR}/water_use_dcs_pps_operational_baseline.csv\", index=False)\n",
    "combined_dcs_pps_planned.to_csv(f\"{OUTPUT_DIR}/water_use_dcs_pps_planned_baseline.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate on average what percent of water use is direct vs indirect\n",
    "data_centers_baseline[\"annual_direct_water_use_m3\"].sum() / data_centers_baseline[\"total_water_use_m3\"].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "30% of water withdrawal occurs for on-site purposes. The rest for electricity generation.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-center-water-footprint",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
